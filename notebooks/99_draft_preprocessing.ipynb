{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea3c0f9f",
   "metadata": {},
   "source": [
    "Get cleaned data into dataframe\n",
    "\n",
    "Numerical transformations\n",
    "\n",
    "- Scaling (standardization, normalization)\n",
    "- Log transforms (reduce skewness)\n",
    "- Binning\n",
    "- Polynomial features\n",
    "\n",
    "Categorical transformations\n",
    "\n",
    "- One-hot encoding\n",
    "- Dummy encoding\n",
    "- Label encoding\n",
    "- Target/frequency encoding\n",
    "\n",
    "Other steps\n",
    "\n",
    "- Train-test split\n",
    "- Handling imbalance\n",
    "- Feature selection\n",
    "- Feature engineering\n",
    "\n",
    "Goal:\n",
    "➡️ Convert cleaned data into a form where models can learn patterns effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e6d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_preprocessed = pd.read_csv('../data/2_cleaned/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e14a16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['postal_code', 'price', 'number_of_rooms', 'living_area', 'equipped_kitchen', 'furnished', 'open_fire', 'terrace', 'garden', 'number_of_facades', 'swimming_pool', 'garden_surface', 'terrace_surface']\n",
      "Categorical features: ['property_id', 'locality_name', 'type_of_property', 'subtype_of_property', 'state_of_building']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "numeric_features = df_preprocessed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = df_preprocessed.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7834de",
   "metadata": {},
   "source": [
    "Numeric transformations\n",
    "- Scaling (standardization, normalization)\n",
    "- Log transforms (reduce skewness)\n",
    "- Binning\n",
    "- Polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59efe89",
   "metadata": {},
   "source": [
    "Scaling pipelines:\n",
    "\n",
    "StandardScaler and MinMaxScaler are two common preprocessing techniques in machine learning:\n",
    "\n",
    "StandardScaler → transforms features to mean = 0 and standard deviation = 1\n",
    "\n",
    "MinMaxScaler → scales features to a fixed range (default 0–1)\n",
    "\n",
    "By putting them in a Pipeline, you create a reusable transformation that can be easily fit and applied to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ddfd38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Standardization\n",
    "standard_scaler = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Normalization\n",
    "minmax_scaler = Pipeline([\n",
    "    (\"scaler\", MinMaxScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f99f75",
   "metadata": {},
   "source": [
    "Pipelines keep preprocessing and modeling consistent\n",
    "\n",
    "When you train a model, you should apply exactly the same scaling to:\n",
    "\n",
    "training data\n",
    "\n",
    "validation/test data\n",
    "\n",
    "future inference data\n",
    "\n",
    "Pipelines make this automatic:\n",
    "fit learns the scaling parameters → transform applies them.\n",
    "\n",
    "Pipelines:\n",
    "ensure consistent preprocessing\n",
    "prevent data leakage\n",
    "integrate nicely with ML models\n",
    "make experimentation easy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f480f",
   "metadata": {},
   "source": [
    "Log Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b56f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "log_transformer = Pipeline([\n",
    "    (\"log\", FunctionTransformer(np.log1p, validate=False)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fbfba",
   "metadata": {},
   "source": [
    "Power transformer: better for automated skew handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "power_transformer = Pipeline([\n",
    "    (\"power\", PowerTransformer()), \n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56c4e4",
   "metadata": {},
   "source": [
    "Binning (Discrezation)\n",
    "Useful for turning numeric values into ordered categories.\n",
    "\n",
    "Example: bin living_area into size categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7beea6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "binning_pipe = Pipeline([\n",
    "    (\"binning\", KBinsDiscretizer(\n",
    "        n_bins=5,\n",
    "        encode=\"ordinal\",\n",
    "        strategy=\"quantile\"\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d3506",
   "metadata": {},
   "source": [
    "Polynomial Features (interaction terms, squared terms)\n",
    "Useful for linear models when relationships are non-linear.\n",
    "\n",
    "Best practices:\n",
    "\n",
    "Use degree 2 only (degree 3+ becomes explosive)\n",
    "\n",
    "Works best for:\n",
    "\n",
    "Linear Regression\n",
    "Ridge / Lasso\n",
    "SVR\n",
    "\n",
    "Do NOT use polynomial features with tree-based models (RandomForest, XGBoost, etc.) — trees learn nonlinear shapes automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92f6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_transformer = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(\n",
    "        degree=2,\n",
    "        include_bias=False,\n",
    "        interaction_only=False\n",
    "    )),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48d602b",
   "metadata": {},
   "source": [
    "Combine all numeric transformations:\n",
    "\n",
    "log transform → scaling → polynomial features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4decab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"log\", FunctionTransformer(np.log1p, validate=False)),  # reduce skew\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
